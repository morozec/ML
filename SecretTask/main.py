Python 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 11:57:41) [MSC v.1900 64 bit (AMD64)] on win32
Type "copyright", "credits" or "license()" for more information.
>>> import os
>>> 
>>> os.chdir("D:\OneDrive\ML\SecretTask")
>>> import pandas
>>> import numpy as np
>>> X_train = pandas.read_csv("x_train.csv")
>>> X_train.head()
  -1.35173485;1.50224188;2.04951167;0.43759658;0.24381777;4.98250337;-1.49303907;1.86857242;1.43587640;3.59471723;0.00000000;-0.11311067;3.19924316;5.17263522;101.96871999;1.65006757;0.30453560;42.90282491;3.98865499;1.74402272;0.62007678;0.08419971;0.71159429;0.18566497;2.74609765;3.52063244;-2.43704329;2.75773330;3.50284619;7.02306583;-1.33716746;0.99955064;5.07788200;5.89387305;2.21054567;1.50627169;4.64337770;1.41284799;2.58082721;0.68007506;0.88841220;5.27688864;2.53862480;3.37496764;1.42770931;1.87616245;1.92331656;1.16262993;0.99881725;1.81156930;1.95309516;-1.54922373;0.26734120;2.32069244;-0.25573198;0.85980910;3.76856966;5.09696346;1.06444401;2.53039936;0.94003950;-0.01933957;0.59424808;3.52308441;1.71762751;2.42316283;5.47690743;0.32436299;0.58157175;0.88148473;-1.42823254;3.25641216;2.44558158;2.46430659;1.19724579;0.38867716;0.92818241;3.53779487;3.43094861;1.58515656;16.80151146;3.00231672;0.42466398;6.93565719;4.52709809;4.46935545;0.90695000;3.06865748;0.01063144;4.38111664;5.32147000;0.76867709;1.29235287;0.94107084;3.78386725;0.49469311;0.13967430;0.75565189;2.71067889;5.10556347;1.05382528;1.66983807;2.00456630;3.87392977;2.58687922;3.36521200;0.66466219;2.10394977;3.84960248;1.12319090;0.26586447;0.73893369;0.76461397;5.71603403;1.91466920;-0.00952951;1.06149873;1.43386290;1.13297025;1.02096394;-0.92584793;0.69530553;1.95395995;1.05822293;1.36303427;1.27884478;1.17050689;3.50950271;1.97367535;0.62685133;1.76913852;1.67151818;0.63417327;0.50178512;2.78859155;-0.95056799;2.23818399;1.27674858;-1.16692137;4.22595771;0.34335190;2.26223479;1.28401692;0.35242162;2.45311676;0.33843005;4.30365936;2.56002021;4.31573366;0.84003276;5.85987789;15.92424879;1.30998953;0.37332236;4.27285923;1.62503893;-0.01500641;-0.18820612;0.10112126;0.93030374;0.88321527;0.96651264;1.97204835;3.95202705;1.45893590;2.78552792;9.28217858;1.54972649;3.39504377;2.54495414;0.78170248;2.86840762;3.97598681;1.43332864;3.88404493;0.60428366;4.35415342;2.84781251;1.53687889;2.02291141;3.55915777;0.13550628;0.04901614;-1.61792076;3.54891424;3.17318509;2.98122777;2.74601466;3.18485182;2.46458682;1.57394665;3.71669306;0.10585688;-1.63992889;0.81375260;1.26211733;0.85267006;0.15010427;-0.39867571;1.81811975;0.71220992;6.34219381;0.83866158;41.47396798;2.15594155;4.81353405;1.33578336;0.65687775;-1.77220747;6.03100800;1.33587822;0.03261604;5.74072795;3.70600725;-0.78906566;4.19348072;2.80305834;0.68500260;3.20449187;3.52808461;4.87795126;0.93752928;0.73046956
0  2.81047260;1.31259056;1.39265240;0.16384002;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
1  2.32878809;-1.92845940;-2.06453246;0.73132270;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
2  -0.12810555;-2.07268765;-2.40760215;0.97855042...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3  1.88682063;0.75792329;-0.09754671;0.46571931;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
4  -1.09361266;1.74758304;2.49960891;0.36679883;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
>>> X_train
     -1.35173485;1.50224188;2.04951167;0.43759658;0.24381777;4.98250337;-1.49303907;1.86857242;1.43587640;3.59471723;0.00000000;-0.11311067;3.19924316;5.17263522;101.96871999;1.65006757;0.30453560;42.90282491;3.98865499;1.74402272;0.62007678;0.08419971;0.71159429;0.18566497;2.74609765;3.52063244;-2.43704329;2.75773330;3.50284619;7.02306583;-1.33716746;0.99955064;5.07788200;5.89387305;2.21054567;1.50627169;4.64337770;1.41284799;2.58082721;0.68007506;0.88841220;5.27688864;2.53862480;3.37496764;1.42770931;1.87616245;1.92331656;1.16262993;0.99881725;1.81156930;1.95309516;-1.54922373;0.26734120;2.32069244;-0.25573198;0.85980910;3.76856966;5.09696346;1.06444401;2.53039936;0.94003950;-0.01933957;0.59424808;3.52308441;1.71762751;2.42316283;5.47690743;0.32436299;0.58157175;0.88148473;-1.42823254;3.25641216;2.44558158;2.46430659;1.19724579;0.38867716;0.92818241;3.53779487;3.43094861;1.58515656;16.80151146;3.00231672;0.42466398;6.93565719;4.52709809;4.46935545;0.90695000;3.06865748;0.01063144;4.38111664;5.32147000;0.76867709;1.29235287;0.94107084;3.78386725;0.49469311;0.13967430;0.75565189;2.71067889;5.10556347;1.05382528;1.66983807;2.00456630;3.87392977;2.58687922;3.36521200;0.66466219;2.10394977;3.84960248;1.12319090;0.26586447;0.73893369;0.76461397;5.71603403;1.91466920;-0.00952951;1.06149873;1.43386290;1.13297025;1.02096394;-0.92584793;0.69530553;1.95395995;1.05822293;1.36303427;1.27884478;1.17050689;3.50950271;1.97367535;0.62685133;1.76913852;1.67151818;0.63417327;0.50178512;2.78859155;-0.95056799;2.23818399;1.27674858;-1.16692137;4.22595771;0.34335190;2.26223479;1.28401692;0.35242162;2.45311676;0.33843005;4.30365936;2.56002021;4.31573366;0.84003276;5.85987789;15.92424879;1.30998953;0.37332236;4.27285923;1.62503893;-0.01500641;-0.18820612;0.10112126;0.93030374;0.88321527;0.96651264;1.97204835;3.95202705;1.45893590;2.78552792;9.28217858;1.54972649;3.39504377;2.54495414;0.78170248;2.86840762;3.97598681;1.43332864;3.88404493;0.60428366;4.35415342;2.84781251;1.53687889;2.02291141;3.55915777;0.13550628;0.04901614;-1.61792076;3.54891424;3.17318509;2.98122777;2.74601466;3.18485182;2.46458682;1.57394665;3.71669306;0.10585688;-1.63992889;0.81375260;1.26211733;0.85267006;0.15010427;-0.39867571;1.81811975;0.71220992;6.34219381;0.83866158;41.47396798;2.15594155;4.81353405;1.33578336;0.65687775;-1.77220747;6.03100800;1.33587822;0.03261604;5.74072795;3.70600725;-0.78906566;4.19348072;2.80305834;0.68500260;3.20449187;3.52808461;4.87795126;0.93752928;0.73046956
0     2.81047260;1.31259056;1.39265240;0.16384002;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
1     2.32878809;-1.92845940;-2.06453246;0.73132270;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
2     -0.12810555;-2.07268765;-2.40760215;0.97855042...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3     1.88682063;0.75792329;-0.09754671;0.46571931;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
4     -1.09361266;1.74758304;2.49960891;0.36679883;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
5     0.71760095;-1.30711698;-2.15681966;0.33700593;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
6     4.60060308;-1.60544855;-1.88996123;0.94500124;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
7     -0.84223064;2.78233537;3.07299711;0.31470071;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
8     -0.71236435;0.53140549;0.46677096;0.12320728;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
9     -0.35333909;1.12463059;1.70104349;0.89084673;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
10    3.04322100;-1.36878116;-2.31056167;0.81178387;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
11    -1.04088918;-1.97497570;-1.93285343;0.54101882...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
12    -0.41624939;0.54592833;0.95458283;0.40004902;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
13    -1.77706795;0.29061278;0.68186697;0.17430716;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
14    -0.21096148;0.34642604;0.62873623;-0.02643062;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
15    0.91629195;-1.62079326;-2.18146622;0.58571466;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
16    1.82097234;2.31456656;2.48620295;0.82613456;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
17    1.37428907;-1.68354369;-1.80058971;0.45558942;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
18    -0.27134140;0.32764846;-0.57457237;0.66515369;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
19    -1.27125108;4.58232008;5.52773096;0.08928732;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
20    0.71330944;1.83448468;2.19777526;0.78356598;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
21    0.73349901;2.33002796;2.84066276;0.06729962;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
22    1.24704224;0.51235435;1.03210880;0.73958519;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
23    -1.37506206;1.94048734;2.95543266;0.54882196;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
24    -0.39338734;0.93751059;1.23144429;0.67830114;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
25    2.11570020;2.33446681;2.80343137;0.61299595;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
26    2.20689976;-1.88050269;-2.96376505;0.49393486;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
27    -1.22839091;0.23753485;0.46025498;0.88576462;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
28    -0.67355164;0.86805526;1.66952822;0.70263106;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
29    1.72875093;0.86651826;0.13682095;0.26372240;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
...                                                 ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3458  1.49551263;3.10267750;4.19345032;0.42233960;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3459  1.91925866;1.65399066;1.71156558;0.10646548;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3460  0.42242854;1.21903953;1.50268017;0.70004929;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3461  -0.97029358;2.37484321;2.72949519;0.82878049;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3462  1.82737346;-1.53054617;-2.21724100;0.42500949;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3463  -0.79906296;-0.98150560;-1.77745799;0.98624758...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3464  1.33716801;-1.08840809;-1.58641391;0.76575517;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3465  2.78451466;0.03183115;0.13772318;0.59931873;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3466  -1.07238637;2.68848127;3.58966819;0.67962893;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3467  1.17931136;-0.84791399;-1.60499799;0.72384022;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3468  3.05115850;-0.52788184;-0.35775357;-0.00107346...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3469  -0.51527172;2.16915513;1.67811161;0.46637301;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3470  2.94903179;1.50177347;1.23050667;0.51783609;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3471  -1.29503167;0.10957069;-0.01957212;0.60084551;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3472  0.14174754;1.31788948;1.60932855;0.74873797;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3473  -1.27866902;0.48242623;0.13313892;0.70702599;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3474  -0.74948716;0.53095034;-0.01513870;0.33421470;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3475  1.50725924;-1.25781705;-1.81061758;0.37371325;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3476  1.61638982;-0.13600089;-0.03085759;0.06937595;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3477  -0.26890991;-1.50061789;-2.38368885;0.32430588...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3478  0.98671737;0.64442918;0.64122680;0.90852519;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3479  -0.94784103;0.72376908;1.81310018;0.85634870;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3480  -1.22040294;2.69163884;2.86070170;0.98813834;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3481  -0.83426385;2.91550757;3.52470669;0.55935779;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3482  3.37831354;-0.18204669;0.32388641;0.06392849;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3483  -1.06862785;3.27116357;3.58400685;0.33779772;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3484  0.17917708;-2.38310186;-2.85330648;0.65192070;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3485  -0.70320924;2.56268865;2.54697941;0.71077261;0...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3486  0.17024201;-1.31337651;-1.53867179;0.18174989;...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            
3487  0.55890601;1.05591846;1.30999780;0.72425906;0....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            

[3488 rows x 1 columns]
>>> X_train = pandas.read_csv("x_train.csv", sep=';', header=None)
>>> X_train.shape
(3489, 223)
>>> X_train.head()
        0         1         2         3         4         5         6    \
0 -1.351735  1.502242  2.049512  0.437597  0.243818  4.982503 -1.493039   
1  2.810473  1.312591  1.392652  0.163840  0.654384 -2.725782  3.195347   
2  2.328788 -1.928459 -2.064532  0.731323  0.117712 -1.567757  2.961654   
3 -0.128106 -2.072688 -2.407602  0.978550  0.111442  2.608775 -1.299084   
4  1.886821  0.757923 -0.097547  0.465719  0.621116 -0.332968  2.446465   

        7         8         9      ...          213       214       215  \
0  1.868572  1.435876  3.594717    ...     3.706007 -0.789066  4.193481   
1  1.910067  0.321657  0.256354    ...    -1.442361  4.913119 -1.182302   
2 -3.013697  0.185553  5.821898    ...    -1.373806  1.991433 -2.514600   
3 -1.919077  1.566608  2.349346    ...     0.295274 -2.896897 -1.639309   
4 -0.143173  0.032383  0.837508    ...    -0.340020  1.320251  0.447317   

        216       217       218       219       220       221       222  
0  2.803058  0.685003  3.204492  3.528085  4.877951  0.937529  0.730470  
1  1.540444  0.563015  1.976227  0.854290  0.490507 -0.190323  1.244596  
2 -2.660716  1.124836 -2.993835 -1.519144  1.851507  0.058385  0.706138  
3 -2.186183 -0.097270 -3.085381 -0.802771  4.713787  0.943972 -0.320782  
4 -0.103243  1.285391 -0.445947 -0.459055 -2.744683  0.620512  1.166808  

[5 rows x 223 columns]
>>> y_train = pandas.read_csv("y_train.csv", sep=';', header=None)
>>> y_train.shape
(3489, 1)
>>> X_test = pandas.read_csv("x_test.csv", sep=';', header=None)
>>> X_test.shape
(2327, 223)
>>> from sklearn.model_selection import train_test_split
>>> from sklearn.model_selection import train_test_split
>>> y_train
      0
0     2
1     3
2     2
3     1
4     2
5     2
6     2
7     4
8     1
9     2
10    2
11    1
12    1
13    2
14    5
15    2
16    2
17    2
18    2
19    1
20    1
21    1
22    1
23    1
24    2
25    1
26    2
27    2
28    1
29    1
...  ..
3459  2
3460  2
3461  3
3462  3
3463  2
3464  1
3465  3
3466  3
3467  2
3468  1
3469  4
3470  2
3471  2
3472  2
3473  1
3474  2
3475  1
3476  2
3477  2
3478  2
3479  2
3480  2
3481  2
3482  3
3483  3
3484  2
3485  1
3486  1
3487  2
3488  2

[3489 rows x 1 columns]
>>> X_train = np.array(X_train)
>>> X_train.shape
(3489, 223)
>>> y_train = np.array(y_train)
>>> X_test = np.array(X_test)
>>> X_train, X_cv, y_train, y_cv = train_test_split(X_train,y_train, test_size = 0.8, random_state = 241)
>>> X = np.array(pandas.read_csv("x_train.csv", sep=';', header=None))
>>> y = np.array(pandas.read_csv("y_train.csv", sep=';', header=None))
>>> X_test = np.array(pandas.read_csv("x_test.csv", sep=';', header=None))
>>> X_train, X_cv, y_train, y_cv = train_test_split(X,y, test_size = 0.8, random_state = 241)
>>> from sklearn.ensemble import RandomForestClassifier
>>> rfc = RandomForestClassifier(n_estimators = 36, random_state = 241)
>>> rfc.fit(X_train,y_train)

Warning (from warnings module):
  File "__main__", line 1
DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=36, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> X_train.shape
(697, 223)
>>> y_train.shape
(697, 1)
>>> y_train = y_train.ravel()
>>> y_train.shape
(697,)
>>> rfc.fit(X_train,y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=36, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred_train = rfc.predict_proba(X_train)
>>> pred_cv = rfc.predict_proba(X_cv)
>>> from sklearn.metrics import log_loss
>>> ll_train = log_loss(y_train, pred_train)
>>> ll_cv = log_loss(y_cv, pred_cv)
>>> ll_train
0.26026626827880628
>>> ll_cv
1.4736393081451826
>>> rfc = RandomForestClassifier(n_estimators = 500, random_state = 241)
>>> rfc.fit(X_train,y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=500, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred_train = rfc.predict_proba(X_train)
>>> pred_cv = rfc.predict_proba(X_cv)
>>> ll_train = log_loss(y_train, pred_train)
>>> ll_cv = log_loss(y_cv, pred_cv)
>>> ll_train
0.25794632838503989
>>> ll_cv
1.0682115473945801
>>> rfc = RandomForestClassifier(n_estimators = 1000, random_state = 241)
>>> rfc.fit(X_train,y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=1000, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred_train = rfc.predict_proba(X_train)
>>> pred_cv = rfc.predict_proba(X_cv)
>>> ll_train = log_loss(y_train, pred_train)
>>> ll_cv = log_loss(y_cv, pred_cv)
>>> ll_train
0.25872968241827288
>>> ll_cv
1.0681098513641007
>>> X_train, X_cv, y_train, y_cv = train_test_split(X,y, test_size = 0.7, random_state = 241)
>>> rfc = RandomForestClassifier(n_estimators = 1000, random_state = 241)
>>> rfc.fit(X_train,y_train)

Warning (from warnings module):
  File "__main__", line 1
DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=1000, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> y_train = y_train.ravel()
>>> rfc.fit(X_train,y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=1000, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred_train = rfc.predict_proba(X_train)
>>> pred_cv = rfc.predict_proba(X_cv)
>>> ll_train = log_loss(y_train, pred_train)
>>> ll_cv = log_loss(y_cv, pred_cv)
>>> ll_train
0.25306340996344068
>>> ll_cv
1.0549808916398795
>>> pred_test = rfc.predict(X_test)
>>> pred_test.shape
(2327,)
>>> f = open('res.txt', 'w')
>>> f.write(pred_test)
Traceback (most recent call last):
  File "<pyshell#72>", line 1, in <module>
    f.write(pred_test)
TypeError: write() argument must be str, not numpy.ndarray

>>> pred_cv
array([[ 0.448,  0.425,  0.083,  0.012,  0.032],
       [ 0.252,  0.422,  0.292,  0.027,  0.007],
       [ 0.372,  0.395,  0.169,  0.033,  0.031],
       ..., 
       [ 0.485,  0.342,  0.113,  0.04 ,  0.02 ],
       [ 0.348,  0.483,  0.132,  0.024,  0.013],
       [ 0.237,  0.48 ,  0.214,  0.033,  0.036]])
>>> pred_train = rfc.predict(X_train)
>>> max(pred_train)
5
>>> max(pred_test)
5
>>> pred_test
array([1, 1, 2, ..., 3, 3, 1], dtype=int64)
>>> f = open('res.txt', 'w')
>>> for item in pred_test:
	print>>f, item

	
Traceback (most recent call last):
  File "<pyshell#85>", line 2, in <module>
    print>>f, item
TypeError: unsupported operand type(s) for >>: 'builtin_function_or_method' and '_io.TextIOWrapper'
>>> for item in pred_test:
	print(f, item)

	


>>> f.close
<built-in method close of _io.TextIOWrapper object at 0x00000000073773A8>
>>> f.close()
>>> from sklearn.ensemble import GradientBoostingClassifier
>>> X.shape
(3489, 223)
>>> y.shape
(3489, 1)
>>> y = y.ravel()
>>> rfc.fit(X,y)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=1000, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred = rfc.predict_proba(X)
>>> ll = log_loss(y, pred)
>>> ll
0.24332139760172394
>>> pred_test = rfc.predict(X_test)
>>> pred_test.chape
Traceback (most recent call last):
  File "<pyshell#99>", line 1, in <module>
    pred_test.chape
AttributeError: 'numpy.ndarray' object has no attribute 'chape'
>>> pred_test.shape
(2327,)
>>> np.savetxt('res1.txt', pred_test)
>>> np.savetxt('res1.txt', pred_test, delimeter='\n')
Traceback (most recent call last):
  File "<pyshell#102>", line 1, in <module>
    np.savetxt('res1.txt', pred_test, delimeter='\n')
TypeError: savetxt() got an unexpected keyword argument 'delimeter'
>>> np.savetxt('res1.txt', pred_test, delimiter='\n')
>>> np.savetxt('res1.txt', pred_test, delimiter='/n')
>>> np.savetxt('res1.txt', pred_test, newline='\n')
>>> np.savetxt('res1.txt', pred_test, newline='\n', fmt='%.')
Traceback (most recent call last):
  File "<pyshell#106>", line 1, in <module>
    np.savetxt('res1.txt', pred_test, newline='\n', fmt='%.')
  File "D:\Anaconda3\lib\site-packages\numpy\lib\npyio.py", line 1158, in savetxt
    fh.write(asbytes(format % tuple(row) + newline))
ValueError: incomplete format
>>> np.savetxt('res1.txt', pred_test, newline='\n', fmt='%.0e')
>>> with open('res2.txt', 'w') as file_handler:
    for item in pred_test:
        file_handler.write("{}\n".format(item))

        
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
>>> gbc = GradientBoostingClassifier(n_estimators = 250, verbose = True, random_state = 241, learning_rate = 1)
>>> gbc.fit(X_train, y_train)
      Iter       Train Loss   Remaining Time 
         1        1022.4015           32.37s
         2         820.9944           25.42s
         3         726.5505           25.20s
         4         656.7396           27.19s
         5         545.9214           26.07s
         6         566.8986           25.13s
         7         508.7888           24.75s
         8         375.5393           24.72s
         9         335.9704           25.66s
        10         289.1611           24.82s
        20         105.9855           20.28s
        30          46.2894           18.08s
        40          22.1456           15.70s
        50          11.2849           13.77s
        60           5.6755           12.30s
        70           2.9406           11.13s
        80           1.4937           10.16s
        90           0.8277            9.28s
       100           0.4633            8.49s
       200           0.3145            1.53s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
>>> pred_train = gbc.predict_proba(X_train)
>>> pred_cv = gbc.predict_proba(X_cv)
>>> ll_train = log_loss(y_train, pred_train)
>>> ll_cv = log_loss(y_cv, pred_cv)
>>> ll_train
0.00030062333061865889
>>> ll_cv
3.7564737015828231
>>> y_train.shape
(1046,)
>>> y_cv.shape
(2443, 1)
>>> y.shape
(3489,)
>>> X_train, X_cv, y_train, y_cv = train_test_split(X,y, test_size = 0.7, random_state = 241)
>>> y_train
array([2, 2, 2, ..., 1, 2, 3], dtype=int64)
>>> y_train.shape
(1046,)
>>> y_cv.shape
(2443,)
>>> X_train.shape
(1046, 223)
>>> X_train, X_cv, y_train, y_cv = train_test_split(X,y, test_size = 0.3, random_state = 241)
>>> y_train.shape
(2442,)
>>> gbc = GradientBoostingClassifier(n_estimators = 250, verbose = True, random_state = 241, learning_rate = 1)
>>> gbc.fit(X_train, y_train)
      Iter       Train Loss   Remaining Time 
         1        2559.8669           50.55s
         2        2310.1719           47.87s
         3        2152.2566           48.01s
         4        2003.3731           50.07s
         5        1908.3727           48.27s
         6        1813.7469           48.64s
         7        1724.4282           48.50s
         8        1624.6640           48.34s
         9        1675.0333           48.04s
        10        1450.9645           47.98s
        20         794.6413           43.47s
        30         459.5268           41.25s
        40         283.6278           38.85s
        50         186.1750           36.89s
        60         135.5103           34.79s
        70          91.4228           32.82s
        80          66.2048           30.70s
        90          46.4347           28.39s
       100          33.8632           25.78s
       200           1.2931            7.05s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
>>> pred_train = gbc.predict_proba(X_train)
>>> pred_cv = gbc.predict_proba(X_cv)
>>> ll_train = log_loss(y_train, pred_train)
>>> ll_cv = log_loss(y_cv, pred_cv)
>>> ll_train
0.00029790910611480538
>>> ll_cv
3.1852255113332859
>>> y_cv.shape
(1047,)
>>> gbc = GradientBoostingClassifier(n_estimators = 250, verbose = True, random_state = 241, learning_rate = 0.2)
>>> gbc.fit(X_train, y_train)
      Iter       Train Loss   Remaining Time 
         1        3243.6851           53.54s
         2        2979.9425           50.47s
         3        2793.1411           49.98s
         4        2641.2276           49.76s
         5        2526.1711           49.40s
         6        2436.2989           48.93s
         7        2350.5759           49.02s
         8        2282.5968           48.83s
         9        2225.4364           48.66s
        10        2166.7157           48.34s
        20        1820.9003           43.74s
        30        1582.3340           41.26s
        40        1372.8957           38.84s
        50        1207.4443           36.86s
        60        1062.7680           34.82s
        70         947.1882           33.00s
        80         853.1448           31.00s
        90         760.3601           29.06s
       100         683.3633           27.32s
       200         264.6726            9.01s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.2, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
>>> pred_train = gbc.predict_proba(X_train)
>>> pred_cv = gbc.predict_proba(X_cv)
>>> ll_train = log_loss(y_train, pred_train)
>>> ll_cv = log_loss(y_cv, pred_cv)
>>> ll_train
0.070602272392911433
>>> ll_cv
1.3235645692851066
>>> gbc.fit(X, y)
      Iter       Train Loss   Remaining Time 
         1        4642.6012            1.11m
         2        4284.6690            1.16m
         3        4023.5907            1.18m
         4        3834.4385            1.21m
         5        3677.4481            1.20m
         6        3550.8892            1.22m
         7        3452.4089            1.19m
         8        3361.3916            1.23m
         9        3289.6022            1.20m
        10        3225.6909            1.17m
        20        2784.1096            1.03m
        30        2500.0499           57.07s
        40        2266.8133           53.69s
        50        2048.0608           50.54s
        60        1882.0556           47.60s
        70        1712.4255           44.92s
        80        1582.3967           42.36s
        90        1464.4997           39.76s
       100        1348.4412           37.22s
       200         657.7679           12.38s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.2, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
>>> pred_train = gbc.predict_proba(X_train)
>>> pred_cv = gbc.predict_proba(X_cv)
>>> ll_train = log_loss(y_train, pred_train)
>>> ll_cv = log_loss(y_cv, pred_cv)
>>> pred = gbc.predict_proba(X)
>>> ll = log_loss(y,pred)
>>> ll
0.13523694923548862
>>> pred = gbc.predict(X_test)
>>> with open('res3.txt', 'w') as file_handler:
    for item in pred:
        file_handler.write("{}\n".format(item))

        
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
>>> rfc = RandomForestClassifier(n_estimators = 1500, random_state = 241)
>>> rfc.fit(X,y)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=1500, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred_pob = rfc.predict_proba(X)
>>> ll = log_loss(y, pred_pob)
>>> ll
0.24337837783988686
>>> rfc = RandomForestClassifier(n_estimators = 500, random_state = 241)
>>> rfc.fit(X,y)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=500, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred_pob = rfc.predict_proba(X)
>>> ll = log_loss(y, pred_pob)
>>> ll
0.24365619741116229
>>> rfc = RandomForestClassifier(n_estimators = 2000, random_state = 241)
>>> rfc.fit(X,y)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=2000, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred_pob = rfc.predict_proba(X)
>>> ll = log_loss(y, pred_pob)
>>> ll
0.24349031024685472
>>> pred = rfc.predict(X_test)
>>> with open('res4.txt', 'w') as file_handler:
    for item in the_list:
        file_handler.write("{}\n".format(item))

        
Traceback (most recent call last):
  File "<pyshell#173>", line 2, in <module>
    for item in the_list:
NameError: name 'the_list' is not defined
>>> with open('res4.txt', 'w') as file_handler:
    for item in pred:
        file_handler.write("{}\n".format(item))

        
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
>>> learning_rates = [1, 0.5, 0.3, 0.2, 0.1]
>>> plt.figure()
Traceback (most recent call last):
  File "<pyshell#183>", line 1, in <module>
    plt.figure()
NameError: name 'plt' is not defined
>>> import matplotlib.pyplot as plt
>>> plt.figure()
<matplotlib.figure.Figure object at 0x0000000007298048>
>>> for lr in learning_rates:
	gbc = GradientBoostingClassifier(n_estimators = 50, verbose = True, random_state = 241, learning_rate = lr)
	gbc.fit(X_train, y_train)
	test_loss=[]
	train_loss = []
	for i, y_pred in enumerate(gbc.staged_decision_function(X_test)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_test, y_pred_sigm)
		test_loss.append(tl)
	for i, y_pred in enumerate(gbc.staged_decision_function(X_train)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_train, y_pred_sigm)
		train_loss.append(tl)
	plt.plot(test_loss, 'r', linewidth=2)
	plt.plot(train_loss, 'g', linewidth=2)
	plt.legend(['test-'+str(lr), 'train'+str(lr)])

	
      Iter       Train Loss   Remaining Time 
         1        2559.8669            9.31s
         2        2310.1719            9.41s
         3        2152.2566            9.24s
         4        2003.3731            9.06s
         5        1908.3727            8.87s
         6        1813.7469            8.80s
         7        1724.4282            8.52s
         8        1624.6640            8.37s
         9        1675.0333            8.15s
        10        1450.9645            8.17s
        20         794.6413            5.77s
        30         459.5268            3.78s
        40         283.6278            1.87s
        50         186.1750            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
Traceback (most recent call last):
  File "<pyshell#190>", line 9, in <module>
    tl = log_loss(y_test, y_pred_sigm)
NameError: name 'y_test' is not defined
>>> for lr in learning_rates:
	gbc = GradientBoostingClassifier(n_estimators = 50, verbose = True, random_state = 241, learning_rate = lr)
	gbc.fit(X_train, y_train)
	test_loss=[]
	train_loss = []
	for i, y_pred in enumerate(gbc.staged_decision_function(X_cv)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_cv, y_pred_sigm)
		test_loss.append(tl)
	for i, y_pred in enumerate(gbc.staged_decision_function(X_train)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_train, y_pred_sigm)
		train_loss.append(tl)
	plt.plot(test_loss, 'r', linewidth=2)
	plt.plot(train_loss, 'g', linewidth=2)
	plt.legend(['test-'+str(lr), 'train'+str(lr)])

	
      Iter       Train Loss   Remaining Time 
         1        2559.8669           10.39s
         2        2310.1719            9.79s
         3        2152.2566            9.40s
         4        2003.3731            9.17s
         5        1908.3727            8.95s
         6        1813.7469            8.99s
         7        1724.4282            8.66s
         8        1624.6640            8.44s
         9        1675.0333            8.23s
        10        1450.9645            8.20s
        20         794.6413            5.79s
        30         459.5268            3.78s
        40         283.6278            1.88s
        50         186.1750            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 8
RuntimeWarning: overflow encountered in exp

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x0000000008480080>]
[<matplotlib.lines.Line2D object at 0x00000000006ACB70>]
<matplotlib.legend.Legend object at 0x0000000008458860>
      Iter       Train Loss   Remaining Time 
         1        2813.2137            9.46s
         2        2478.0492            9.31s
         3        2301.9229            9.21s
         4        2172.4526            9.15s
         5        2065.5605            8.91s
         6        1960.0639            8.76s
         7        1868.9826            8.55s
         8        1800.9139            8.37s
         9        1729.7074            8.17s
        10        1684.9251            7.95s
        20        1192.1627            5.75s
        30         844.9640            3.77s
        40         641.6909            1.86s
        50         494.9863            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x00000000072249B0>]
[<matplotlib.lines.Line2D object at 0x000000000841D7F0>]
<matplotlib.legend.Legend object at 0x0000000008480940>
      Iter       Train Loss   Remaining Time 
         1        3075.2118            9.46s
         2        2764.7488            9.50s
         3        2561.8822            9.24s
         4        2421.2003            9.14s
         5        2315.2504            8.91s
         6        2224.1301            8.81s
         7        2151.6590            8.59s
         8        2082.2559            8.36s
         9        2017.2936            8.21s
        10        1968.9004            7.97s
        20        1579.0625            5.70s
        30        1293.1938            3.75s
        40        1065.4367            1.86s
        50         872.2039            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.3, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000721DA90>]
[<matplotlib.lines.Line2D object at 0x000000000A022B38>]
<matplotlib.legend.Legend object at 0x000000000722DFD0>
      Iter       Train Loss   Remaining Time 
         1        3243.6851            9.60s
         2        2979.9425            9.65s
         3        2793.1411            9.34s
         4        2641.2276            9.17s
         5        2526.1711            8.97s
         6        2436.2989            8.81s
         7        2350.5759            8.59s
         8        2282.5968            8.41s
         9        2225.4364            8.22s
        10        2166.7157            8.02s
        20        1820.9003            5.76s
        30        1582.3340            3.77s
        40        1372.8957            1.86s
        50        1207.4443            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.2, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000722D438>]
[<matplotlib.lines.Line2D object at 0x000000000721DA58>]
<matplotlib.legend.Legend object at 0x000000000A0459E8>
      Iter       Train Loss   Remaining Time 
         1        3435.2390            9.90s
         2        3263.5674            9.55s
         3        3123.4794            9.35s
         4        3003.6245            9.26s
         5        2900.9931            9.02s
         6        2813.7844            8.81s
         7        2735.4041            8.63s
         8        2663.8077            8.43s
         9        2602.9532            8.21s
        10        2547.2556            8.02s
        20        2184.5594            5.83s
        30        1982.8803            3.82s
        40        1843.0870            1.88s
        50        1705.2304            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000721D908>]
[<matplotlib.lines.Line2D object at 0x000000000F3631D0>]
<matplotlib.legend.Legend object at 0x000000000F363C18>
>>> plt.show()
>>> plt.show()
>>> counter = 1
>>> legend=[]
>>> 
KeyboardInterrupt
plt.legend(['test-'+str(lr), 'train'+str(lr)])
>>> for lr in learning_rates:
	gbc = GradientBoostingClassifier(n_estimators = 50, verbose = True, random_state = 241, learning_rate = lr)
	gbc.fit(X_train, y_train)
	test_loss=[]
	train_loss = []
	for i, y_pred in enumerate(gbc.staged_decision_function(X_cv)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_cv, y_pred_sigm)
		test_loss.append(tl)
	for i, y_pred in enumerate(gbc.staged_decision_function(X_train)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_train, y_pred_sigm)
		train_loss.append(tl)
	plt.plot(test_loss, 'r', linewidth=2)
	plt.plot(train_loss, 'g', linewidth=2)
	legend.append(['test-'+str(lr), 'train'+str(lr)])

	
      Iter       Train Loss   Remaining Time 
         1        2559.8669            9.31s
         2        2310.1719            9.24s
         3        2152.2566            9.13s
         4        2003.3731            9.01s
         5        1908.3727            8.94s
         6        1813.7469            8.77s
         7        1724.4282            8.58s
         8        1624.6640            8.43s
         9        1675.0333            8.20s
        10        1450.9645            8.07s
        20         794.6413            5.75s
        30         459.5268            3.75s
        40         283.6278            1.86s
        50         186.1750            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 8
RuntimeWarning: overflow encountered in exp

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000F532E10>]
[<matplotlib.lines.Line2D object at 0x000000000F532FD0>]
      Iter       Train Loss   Remaining Time 
         1        2813.2137            9.90s
         2        2478.0492            9.36s
         3        2301.9229            9.26s
         4        2172.4526            9.12s
         5        2065.5605            8.96s
         6        1960.0639            8.75s
         7        1868.9826            8.57s
         8        1800.9139            8.37s
         9        1729.7074            8.20s
        10        1684.9251            7.98s
        20        1192.1627            5.74s
        30         844.9640            3.75s
        40         641.6909            1.86s
        50         494.9863            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000A04BCC0>]
[<matplotlib.lines.Line2D object at 0x000000000F861208>]
      Iter       Train Loss   Remaining Time 
         1        3075.2118            9.36s
         2        2764.7488            9.48s
         3        2561.8822            9.31s
         4        2421.2003            9.17s
         5        2315.2504            8.89s
         6        2224.1301            8.78s
         7        2151.6590            8.56s
         8        2082.2559            8.36s
         9        2017.2936            8.19s
        10        1968.9004            7.99s
        20        1579.0625            5.73s
        30        1293.1938            3.76s
        40        1065.4367            1.87s
        50         872.2039            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.3, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x0000000007224978>]
[<matplotlib.lines.Line2D object at 0x000000000F86A278>]
      Iter       Train Loss   Remaining Time 
         1        3243.6851            9.60s
         2        2979.9425            9.48s
         3        2793.1411            9.35s
         4        2641.2276            9.18s
         5        2526.1711            9.01s
         6        2436.2989            8.79s
         7        2350.5759            8.59s
         8        2282.5968            8.39s
         9        2225.4364            8.23s
        10        2166.7157            8.00s
        20        1820.9003            5.75s
        30        1582.3340            3.76s
        40        1372.8957            1.86s
        50        1207.4443            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.2, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000F861AC8>]
[<matplotlib.lines.Line2D object at 0x000000000F8722E8>]
      Iter       Train Loss   Remaining Time 
         1        3435.2390            9.60s
         2        3263.5674            9.43s
         3        3123.4794            9.29s
         4        3003.6245            9.25s
         5        2900.9931            9.05s
         6        2813.7844            8.82s
         7        2735.4041            8.64s
         8        2663.8077            8.45s
         9        2602.9532            8.22s
        10        2547.2556            8.03s
        20        2184.5594            5.85s
        30        1982.8803            3.83s
        40        1843.0870            1.89s
        50        1705.2304            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000F86AB38>]
[<matplotlib.lines.Line2D object at 0x000000000F878358>]
>>> plt.legend(legend)
<matplotlib.legend.Legend object at 0x0000000008BA50B8>
>>> plt.show()
>>> legend=[]
>>> for lr in learning_rates:
	gbc = GradientBoostingClassifier(n_estimators = 50, verbose = True, random_state = 241, learning_rate = lr)
	gbc.fit(X_train, y_train)
	test_loss=[]
	train_loss = []
	for i, y_pred in enumerate(gbc.staged_decision_function(X_cv)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_cv, y_pred_sigm)
		test_loss.append(tl)
	for i, y_pred in enumerate(gbc.staged_decision_function(X_train)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_train, y_pred_sigm)
		train_loss.append(tl)
	plt.plot(test_loss, linewidth=2)
	plt.plot(train_loss, linewidth=2)
	legend.append(['test-'+str(lr), 'train'+str(lr)])
plt.legend(legend)
SyntaxError: invalid syntax
>>> for lr in learning_rates:
	gbc = GradientBoostingClassifier(n_estimators = 50, verbose = True, random_state = 241, learning_rate = lr)
	gbc.fit(X_train, y_train)
	test_loss=[]
	train_loss = []
	for i, y_pred in enumerate(gbc.staged_decision_function(X_cv)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_cv, y_pred_sigm)
		test_loss.append(tl)
	for i, y_pred in enumerate(gbc.staged_decision_function(X_train)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_train, y_pred_sigm)
		train_loss.append(tl)
	plt.plot(test_loss, linewidth=2)
	plt.plot(train_loss, linewidth=2)
	legend.append(['test-'+str(lr), 'train'+str(lr)])

      Iter       Train Loss   Remaining Time 
         1        2559.8669            9.46s
         2        2310.1719            9.34s
         3        2152.2566            9.18s
         4        2003.3731            9.09s
         5        1908.3727            8.98s
         6        1813.7469            8.76s
         7        1724.4282            8.58s
         8        1624.6640            8.43s
         9        1675.0333            8.19s
        10        1450.9645            8.01s
        20         794.6413            5.77s
        30         459.5268            3.77s
        40         283.6278            1.87s
        50         186.1750            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 8
RuntimeWarning: overflow encountered in exp

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000FA62198>]
[<matplotlib.lines.Line2D object at 0x000000000FA62390>]
      Iter       Train Loss   Remaining Time 
         1        2813.2137            9.36s
         2        2478.0492            9.46s
         3        2301.9229            9.32s
         4        2172.4526            9.12s
         5        2065.5605            8.97s
         6        1960.0639            8.80s
         7        1868.9826            8.58s
         8        1800.9139            8.35s
         9        1729.7074            8.19s
        10        1684.9251            7.99s
        20        1192.1627            5.74s
        30         844.9640            3.77s
        40         641.6909            1.86s
        50         494.9863            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000F8AEAC8>]
[<matplotlib.lines.Line2D object at 0x000000000FA68588>]
      Iter       Train Loss   Remaining Time 
         1        3075.2118           10.10s
         2        2764.7488            9.67s
         3        2561.8822            9.43s
         4        2421.2003            9.30s
         5        2315.2504            9.00s
         6        2224.1301            8.86s
         7        2151.6590            8.64s
         8        2082.2559            8.43s
         9        2017.2936            8.24s
        10        1968.9004            8.01s
        20        1579.0625            5.74s
        30        1293.1938            3.75s
        40        1065.4367            1.87s
        50         872.2039            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.3, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000F539710>]
[<matplotlib.lines.Line2D object at 0x000000000FA705F8>]
      Iter       Train Loss   Remaining Time 
         1        3243.6851            9.51s
         2        2979.9425            9.94s
         3        2793.1411            9.76s
         4        2641.2276            9.53s
         5        2526.1711            9.24s
         6        2436.2989            8.92s
         7        2350.5759            8.81s
         8        2282.5968            8.56s
         9        2225.4364            8.37s
        10        2166.7157            8.19s
        20        1820.9003            5.91s
        30        1582.3340            3.89s
        40        1372.8957            1.91s
        50        1207.4443            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.2, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000FA68E48>]
[<matplotlib.lines.Line2D object at 0x000000000FA7A668>]
      Iter       Train Loss   Remaining Time 
         1        3435.2390           10.05s
         2        3263.5674            9.98s
         3        3123.4794            9.68s
         4        3003.6245            9.43s
         5        2900.9931            9.23s
         6        2813.7844            9.01s
         7        2735.4041            8.75s
         8        2663.8077            8.56s
         9        2602.9532            8.31s
        10        2547.2556            8.13s
        20        2184.5594            5.95s
        30        1982.8803            3.88s
        40        1843.0870            1.94s
        50        1705.2304            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000FA70EB8>]
[<matplotlib.lines.Line2D object at 0x000000000FA806D8>]
>>> plt.legend(legend)
<matplotlib.legend.Legend object at 0x000000000F8AEBA8>
>>> plt.show()
>>> legend
[['test-1', 'train1'], ['test-0.5', 'train0.5'], ['test-0.3', 'train0.3'], ['test-0.2', 'train0.2'], ['test-0.1', 'train0.1']]
>>> legend=[]
>>> for lr in learning_rates:
	gbc = GradientBoostingClassifier(n_estimators = 50, verbose = True, random_state = 241, learning_rate = lr)
	gbc.fit(X_train, y_train)
	test_loss=[]
	train_loss = []
	for i, y_pred in enumerate(gbc.staged_decision_function(X_cv)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_cv, y_pred_sigm)
		test_loss.append(tl)
	for i, y_pred in enumerate(gbc.staged_decision_function(X_train)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_train, y_pred_sigm)
		train_loss.append(tl)
	plt.plot(test_loss, linewidth=2)
	plt.plot(train_loss, linewidth=2)
	legend.append('test-'+str(lr))
	legend.append('train-'+str(lr))

	
      Iter       Train Loss   Remaining Time 
         1        2559.8669            9.56s
         2        2310.1719            9.29s
         3        2152.2566            9.20s
         4        2003.3731            9.05s
         5        1908.3727            8.88s
         6        1813.7469            8.76s
         7        1724.4282            8.55s
         8        1624.6640            8.39s
         9        1675.0333            8.15s
        10        1450.9645            8.12s
        20         794.6413            5.73s
        30         459.5268            3.75s
        40         283.6278            1.86s
        50         186.1750            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 8
RuntimeWarning: overflow encountered in exp

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000FC8D860>]
[<matplotlib.lines.Line2D object at 0x000000000FC8DA58>]
      Iter       Train Loss   Remaining Time 
         1        2813.2137            9.27s
         2        2478.0492            9.46s
         3        2301.9229            9.20s
         4        2172.4526            9.03s
         5        2065.5605            8.89s
         6        1960.0639            8.71s
         7        1868.9826            8.55s
         8        1800.9139            8.31s
         9        1729.7074            8.18s
        10        1684.9251            7.94s
        20        1192.1627            5.70s
        30         844.9640            3.73s
        40         641.6909            1.85s
        50         494.9863            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000FAB5EB8>]
[<matplotlib.lines.Line2D object at 0x000000000FC96C50>]
      Iter       Train Loss   Remaining Time 
         1        3075.2118            9.51s
         2        2764.7488            9.46s
         3        2561.8822            9.20s
         4        2421.2003            9.12s
         5        2315.2504            8.90s
         6        2224.1301            8.73s
         7        2151.6590            8.52s
         8        2082.2559            8.34s
         9        2017.2936            8.18s
        10        1968.9004            7.95s
        20        1579.0625            5.72s
        30        1293.1938            3.74s
        40        1065.4367            1.85s
        50         872.2039            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.3, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000FC964A8>]
[<matplotlib.lines.Line2D object at 0x000000000FC9DCC0>]
      Iter       Train Loss   Remaining Time 
         1        3243.6851            9.27s
         2        2979.9425            9.53s
         3        2793.1411            9.34s
         4        2641.2276            9.11s
         5        2526.1711            8.94s
         6        2436.2989            8.71s
         7        2350.5759            8.60s
         8        2282.5968            8.36s
         9        2225.4364            8.19s
        10        2166.7157            7.99s
        20        1820.9003            5.70s
        30        1582.3340            3.72s
        40        1372.8957            1.84s
        50        1207.4443            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.2, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000FC9D550>]
[<matplotlib.lines.Line2D object at 0x000000000FCA4D30>]
      Iter       Train Loss   Remaining Time 
         1        3435.2390            9.31s
         2        3263.5674            9.43s
         3        3123.4794            9.28s
         4        3003.6245            9.13s
         5        2900.9931            8.96s
         6        2813.7844            8.77s
         7        2735.4041            8.55s
         8        2663.8077            8.41s
         9        2602.9532            8.18s
        10        2547.2556            7.99s
        20        2184.5594            5.81s
        30        1982.8803            3.79s
        40        1843.0870            1.87s
        50        1705.2304            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000FCA45C0>]
[<matplotlib.lines.Line2D object at 0x000000000FCADDA0>]
>>> legend
['test-1', 'train-1', 'test-0.5', 'train-0.5', 'test-0.3', 'train-0.3', 'test-0.2', 'train-0.2', 'test-0.1', 'train-0.1']
>>> plot.legend(legend)
Traceback (most recent call last):
  File "<pyshell#214>", line 1, in <module>
    plot.legend(legend)
NameError: name 'plot' is not defined
>>> plt.legend(legend)
<matplotlib.legend.Legend object at 0x000000000F8D4F98>
>>> plt.show()
>>> legend=[]
>>> for lr in learning_rates:
	gbc = GradientBoostingClassifier(n_estimators = 250, verbose = True, random_state = 241, learning_rate = lr)
	gbc.fit(X_train, y_train)
	test_loss=[]
	train_loss = []
	for i, y_pred in enumerate(gbc.staged_decision_function(X_cv)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_cv, y_pred_sigm)
		test_loss.append(tl)
	for i, y_pred in enumerate(gbc.staged_decision_function(X_train)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_train, y_pred_sigm)
		train_loss.append(tl)
	plt.plot(test_loss, linewidth=2)
	plt.plot(train_loss, linewidth=2)
	legend.append('test-'+str(lr))
	legend.append('train-'+str(lr))

	
      Iter       Train Loss   Remaining Time 
         1        2559.8669           52.78s
         2        2310.1719           49.12s
         3        2152.2566           49.08s
         4        2003.3731           48.78s
         5        1908.3727           48.57s
         6        1813.7469           48.85s
         7        1724.4282           48.30s
         8        1624.6640           48.32s
         9        1675.0333           48.02s
        10        1450.9645           47.96s
        20         794.6413           43.88s
        30         459.5268           41.11s
        40         283.6278           38.90s
        50         186.1750           37.08s
        60         135.5103           35.15s
        70          91.4228           33.17s
        80          66.2048           31.01s
        90          46.4347           28.52s
       100          33.8632           25.98s
       200           1.2931            7.16s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 8
RuntimeWarning: overflow encountered in exp

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000F8A23C8>]
[<matplotlib.lines.Line2D object at 0x000000000F8A2F60>]
      Iter       Train Loss   Remaining Time 
         1        2813.2137           47.58s
         2        2478.0492           48.37s
         3        2301.9229           48.18s
         4        2172.4526           48.96s
         5        2065.5605           48.86s
         6        1960.0639           49.09s
         7        1868.9826           48.09s
         8        1800.9139           48.02s
         9        1729.7074           48.05s
        10        1684.9251           47.63s
        20        1192.1627           43.56s
        30         844.9640           40.91s
        40         641.6909           38.67s
        50         494.9863           36.67s
        60         388.9619           34.64s
        70         307.9407           32.76s
        80         246.2596           30.93s
        90         198.4523           29.06s
       100         160.1764           27.19s
       200          21.4472            8.89s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000FA3F128>]
[<matplotlib.lines.Line2D object at 0x000000000A01C668>]
      Iter       Train Loss   Remaining Time 
         1        3075.2118           48.22s
         2        2764.7488           49.02s
         3        2561.8822           48.74s
         4        2421.2003           49.18s
         5        2315.2504           48.92s
         6        2224.1301           48.80s
         7        2151.6590           48.45s
         8        2082.2559           48.29s
         9        2017.2936           48.25s
        10        1968.9004           48.13s
        20        1579.0625           44.65s
        30        1293.1938           42.20s
        40        1065.4367           39.83s
        50         872.2039           37.65s
        60         737.4028           35.62s
        70         639.9441           33.58s
        80         553.6090           31.62s
        90         484.2090           29.68s
       100         422.8045           27.81s
       200         113.7497            9.24s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.3, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000FA3F0B8>]
[<matplotlib.lines.Line2D object at 0x000000000F36EEF0>]
      Iter       Train Loss   Remaining Time 
         1        3243.6851           47.48s
         2        2979.9425           48.53s
         3        2793.1411           49.23s
         4        2641.2276           49.05s
         5        2526.1711           48.72s
         6        2436.2989           48.68s
         7        2350.5759           48.41s
         8        2282.5968           48.29s
         9        2225.4364           48.33s
        10        2166.7157           48.01s
        20        1820.9003           43.66s
        30        1582.3340           41.06s
        40        1372.8957           38.77s
        50        1207.4443           36.75s
        60        1062.7680           34.82s
        70         947.1882           32.86s
        80         853.1448           30.94s
        90         760.3601           29.18s
       100         683.3633           27.32s
       200         264.6726            9.06s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.2, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000FA3F160>]
[<matplotlib.lines.Line2D object at 0x0000000007340AC8>]
      Iter       Train Loss   Remaining Time 
         1        3435.2390           49.22s
         2        3263.5674           48.40s
         3        3123.4794           48.82s
         4        3003.6245           48.87s
         5        2900.9931           48.77s
         6        2813.7844           48.76s
         7        2735.4041           48.55s
         8        2663.8077           48.62s
         9        2602.9532           48.39s
        10        2547.2556           48.06s
        20        2184.5594           44.70s
        30        1982.8803           41.96s
        40        1843.0870           39.52s
        50        1705.2304           37.43s
        60        1593.6126           35.28s
        70        1490.2781           33.31s
        80        1399.2009           31.37s
        90        1320.1698           29.40s
       100        1234.1807           27.50s
       200         713.7346            9.05s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=250, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000A01CAC8>]
[<matplotlib.lines.Line2D object at 0x00000000084A30B8>]
>>> plt.legend(legend)
<matplotlib.legend.Legend object at 0x000000000FD12B38>
>>> plt.show()
>>> test_loss
[1.5169628787135383, 1.487932498615407, 1.4619114507362194, 1.4386802103626193, 1.4185689467736387, 1.4000575291119839, 1.3828732357796907, 1.3669763600647962, 1.3519143465330818, 1.3378420853899962, 1.3250507963495042, 1.313211930724574, 1.3019137727988879, 1.2910607253411104, 1.2804281198365819, 1.2715161754090498, 1.2635323448173184, 1.2561842495347055, 1.2497143012331837, 1.2423886584101402, 1.2375894432495518, 1.2320175967388398, 1.2263846360827266, 1.2215297113616566, 1.2170316702006623, 1.211949510924123, 1.2086168870620158, 1.2046423182985804, 1.2011914812276214, 1.1979219163763746, 1.1952534057660449, 1.1927254900826494, 1.1909003467695813, 1.1879542780426575, 1.1861737712748546, 1.1838113555513199, 1.1824489648125855, 1.1796356124059078, 1.1787867990701955, 1.1765637807472376, 1.1747880496907244, 1.172268566196482, 1.1713999910905815, 1.1704292452262011, 1.1687825107856404, 1.1678321766888404, 1.1660153877966539, 1.1647327532005756, 1.1631899750837216, 1.1616348786509125, 1.1609940187476107, 1.1599990304994963, 1.1598560886821472, 1.1586592571458065, 1.1578861831362157, 1.1568459082511262, 1.156425967091923, 1.1554607219523765, 1.1538287270605925, 1.1532901187312772, 1.1522585522115711, 1.1517188969878949, 1.1508474833640365, 1.1505571458354709, 1.1497375518727446, 1.1490206621961572, 1.1487481875379972, 1.1480001573884187, 1.1470940365675195, 1.1466222274023181, 1.1458055775505209, 1.1453909023096156, 1.1446881692348727, 1.1439878327115884, 1.1430893966144828, 1.142746698298593, 1.1421767890660095, 1.1417582122194176, 1.1415203499463478, 1.1413518351478686, 1.1408964289934516, 1.139765375511645, 1.1389547944671576, 1.1381444976833368, 1.1382798126262508, 1.1379030409713631, 1.1378525340310608, 1.1371908261063548, 1.1368862375549225, 1.136586058093743, 1.1361468147604654, 1.1356952173155621, 1.1353602498905284, 1.1349725169279832, 1.1347598224825279, 1.1345263079563435, 1.134353592635043, 1.1336746014653167, 1.1329257600462626, 1.1322850024162785, 1.1317157190771743, 1.1313936983828954, 1.1319235668749372, 1.1315900853822121, 1.1308693625380564, 1.1304333980904833, 1.1295789841488306, 1.1290683244274113, 1.1290710872493912, 1.1289280138482718, 1.1282905114296558, 1.1278917545812055, 1.127644995160022, 1.1270854122494725, 1.1269335010890094, 1.1270255463420307, 1.1268346532386493, 1.1269359988671324, 1.1263836892220951, 1.1249113528920252, 1.123967841115955, 1.1236043253941117, 1.1229557706935023, 1.1223146965018449, 1.1217986876320571, 1.1217854129023572, 1.1216063840421666, 1.121455316671369, 1.1210970575192651, 1.1206740562808439, 1.1202294257390648, 1.1197450077778281, 1.1197513585991643, 1.1193242914832668, 1.1189632299697407, 1.1184169634204144, 1.1181810860885322, 1.1178673373917516, 1.1176337370769904, 1.116836633330845, 1.1168034909154219, 1.1162762114191849, 1.1155801883461003, 1.1141683902750583, 1.114119705274373, 1.1134798285399508, 1.1134168309739041, 1.1131647520663146, 1.1126850288604524, 1.1120570900565268, 1.1115785793930424, 1.1113160237385338, 1.1111494216682638, 1.1111149592048108, 1.111259455557668, 1.1108262761257341, 1.1104486044938859, 1.1103762509535977, 1.1098279094560888, 1.109363138827814, 1.1091271782515983, 1.1092144050386046, 1.109417095223288, 1.1090563936578424, 1.1085041521516252, 1.108131045596132, 1.1076516853787108, 1.1073503648687186, 1.1069069007990178, 1.1064341411252796, 1.1058902174803493, 1.1057205326445139, 1.1054693516834013, 1.1045441404025138, 1.1043929282485589, 1.1040164502586649, 1.103696857073365, 1.1037153951071343, 1.1034852981862957, 1.102826212962946, 1.1027609708965564, 1.1026365002651632, 1.1021437570295449, 1.1014800582037474, 1.10126537600223, 1.1007689402721412, 1.1004263099675773, 1.1000041582832165, 1.0998518073471668, 1.099279062058629, 1.0989903049612455, 1.09872342502142, 1.0989186681393432, 1.0986331105416092, 1.0986676708748282, 1.0985793142553844, 1.0980204453030176, 1.0975818584140336, 1.0977058172634888, 1.0974159290768208, 1.0969912053023483, 1.0962374981892649, 1.0957354319930954, 1.0951721163404298, 1.0945955255279263, 1.0943826182711631, 1.0943523837704474, 1.0939430971978801, 1.0939815801559647, 1.0939373787972613, 1.0937544016513545, 1.0936521222704398, 1.0930154957626064, 1.0927962434407237, 1.0924780996109187, 1.0920057911064638, 1.0915801530680727, 1.0915090851633775, 1.090956281149128, 1.0908523342837948, 1.0907605683525841, 1.0904499995533707, 1.0902758658638414, 1.0901745314196152, 1.0900719739051559, 1.0901108922383311, 1.0899555810422696, 1.0898144419260121, 1.0897151017982902, 1.0898471153831379, 1.0894489502839932, 1.0893520422168856, 1.0890705538573293, 1.0889113752030453, 1.0888571712219448, 1.0886914316027543, 1.0886120595271802, 1.088900208769733, 1.0889991551385299, 1.0889703738448211, 1.0886552074674143, 1.08878243894786, 1.0889712449530444, 1.0890074140566917, 1.088569039177804, 1.0888207315930267, 1.0885062112275592, 1.0882093701353202, 1.0881287497198497, 1.0882862982471146]
>>> rfc = RandomForestClassifier(n_estimators = 1500, random_state = 241)
>>> rfc.fit(X_train,y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=1500, n_jobs=1, oob_score=False, random_state=241,
            verbose=0, warm_start=False)
>>> pred = rfc.predict_proba(X_cv)
>>> ll = log_loss(y_cv, pred)
>>> ll
1.0071992522577746
>>> plt.show()
>>> legend=[]
>>> for lr in learning_rates:
	gbc = GradientBoostingClassifier(n_estimators = 50, verbose = True, random_state = 241, learning_rate = lr)
	gbc.fit(X_train, y_train)
	test_loss=[]
	train_loss = []
	for i, y_pred in enumerate(gbc.staged_decision_function(X_cv)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_cv, y_pred_sigm)
		test_loss.append(tl)
	for i, y_pred in enumerate(gbc.staged_decision_function(X_train)):
		y_pred_arr = np.array(y_pred)
		y_pred_sigm = 1/(1+np.exp(-y_pred_arr))
		tl = log_loss(y_train, y_pred_sigm)
		train_loss.append(tl)
	plt.plot(test_loss, linewidth=2)
	plt.plot(train_loss, linewidth=2)
	legend.append('test-'+str(lr))
	legend.append('train-'+str(lr))

	
      Iter       Train Loss   Remaining Time 
         1        2559.8669            9.70s
         2        2310.1719            9.34s
         3        2152.2566            9.16s
         4        2003.3731            9.06s
         5        1908.3727            8.92s
         6        1813.7469            8.75s
         7        1724.4282            8.54s
         8        1624.6640            8.39s
         9        1675.0333            8.17s
        10        1450.9645            8.13s
        20         794.6413            5.73s
        30         459.5268            3.77s
        40         283.6278            1.87s
        50         186.1750            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 8
RuntimeWarning: overflow encountered in exp

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x0000000008B9D588>]
[<matplotlib.lines.Line2D object at 0x0000000008B9D780>]
      Iter       Train Loss   Remaining Time 
         1        2813.2137            9.80s
         2        2478.0492            9.41s
         3        2301.9229            9.41s
         4        2172.4526            9.07s
         5        2065.5605            8.99s
         6        1960.0639            8.74s
         7        1868.9826            8.62s
         8        1800.9139            8.36s
         9        1729.7074            8.18s
        10        1684.9251            7.96s
        20        1192.1627            5.80s
        30         844.9640            3.76s
        40         641.6909            1.88s
        50         494.9863            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.5, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)

Warning (from warnings module):
  File "__main__", line 13
RuntimeWarning: overflow encountered in exp
[<matplotlib.lines.Line2D object at 0x000000000FA297F0>]
[<matplotlib.lines.Line2D object at 0x0000000007313A90>]
      Iter       Train Loss   Remaining Time 
         1        3075.2118            9.95s
         2        2764.7488            9.67s
         3        2561.8822            9.34s
         4        2421.2003            9.31s
         5        2315.2504            9.04s
         6        2224.1301            8.95s
         7        2151.6590            8.79s
         8        2082.2559            8.53s
         9        2017.2936            8.33s
        10        1968.9004            8.12s
        20        1579.0625            5.77s
        30        1293.1938            3.75s
        40        1065.4367            1.87s
        50         872.2039            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.3, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x0000000008B9DE80>]
[<matplotlib.lines.Line2D object at 0x0000000007299A58>]
      Iter       Train Loss   Remaining Time 
         1        3243.6851            9.11s
         2        2979.9425            9.58s
         3        2793.1411            9.23s
         4        2641.2276            9.13s
         5        2526.1711            9.03s
         6        2436.2989            8.70s
         7        2350.5759            8.68s
         8        2282.5968            8.38s
         9        2225.4364            8.20s
        10        2166.7157            8.02s
        20        1820.9003            5.68s
        30        1582.3340            3.73s
        40        1372.8957            1.85s
        50        1207.4443            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.2, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x0000000007313240>]
[<matplotlib.lines.Line2D object at 0x000000000FC207F0>]
      Iter       Train Loss   Remaining Time 
         1        3435.2390            9.11s
         2        3263.5674            9.34s
         3        3123.4794            9.34s
         4        3003.6245            9.13s
         5        2900.9931            8.98s
         6        2813.7844            8.82s
         7        2735.4041            8.62s
         8        2663.8077            8.45s
         9        2602.9532            8.22s
        10        2547.2556            8.00s
        20        2184.5594            5.77s
        30        1982.8803            3.74s
        40        1843.0870            1.86s
        50        1705.2304            0.00s
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=50, presort='auto', random_state=241,
              subsample=1.0, verbose=True, warm_start=False)
[<matplotlib.lines.Line2D object at 0x000000000F3CB048>]
[<matplotlib.lines.Line2D object at 0x00000000072A9358>]
>>> plt.legend(legend)
<matplotlib.legend.Legend object at 0x0000000008B9DF28>
>>> plt.show()
>>> test_loss
[1.5169628787135383, 1.487932498615407, 1.4619114507362194, 1.4386802103626193, 1.4185689467736387, 1.4000575291119839, 1.3828732357796907, 1.3669763600647962, 1.3519143465330818, 1.3378420853899962, 1.3250507963495042, 1.313211930724574, 1.3019137727988879, 1.2910607253411104, 1.2804281198365819, 1.2715161754090498, 1.2635323448173184, 1.2561842495347055, 1.2497143012331837, 1.2423886584101402, 1.2375894432495518, 1.2320175967388398, 1.2263846360827266, 1.2215297113616566, 1.2170316702006623, 1.211949510924123, 1.2086168870620158, 1.2046423182985804, 1.2011914812276214, 1.1979219163763746, 1.1952534057660449, 1.1927254900826494, 1.1909003467695813, 1.1879542780426575, 1.1861737712748546, 1.1838113555513199, 1.1824489648125855, 1.1796356124059078, 1.1787867990701955, 1.1765637807472376, 1.1747880496907244, 1.172268566196482, 1.1713999910905815, 1.1704292452262011, 1.1687825107856404, 1.1678321766888404, 1.1660153877966539, 1.1647327532005756, 1.1631899750837216, 1.1616348786509125]
>>> from sklearn.neighbors import KNeighborsClassifier
>>> knn = KNeighborsClassifier()
>>> knn.fit(X_train, y_train)
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
>>> y_train_predict = knn.predict(X_train)
>>> y_test_predict = knn.predict(X_test)
>>> err_train = np.mean(y_train != y_train_predict)
>>> err_test  = np.mean(y_test  != y_test_predict)
Traceback (most recent call last):
  File "<pyshell#241>", line 1, in <module>
    err_test  = np.mean(y_test  != y_test_predict)
NameError: name 'y_test' is not defined
>>> y_cv_predict = knn.predict(X_cv)
>>> err_cv  = np.mean(y_cv  != y_cv_predict)
>>> print(err_train, err_cv)
0.406224406224 0.58452722063
>>> y_train.shape
(2442,)
>>> from sklearn.grid_search import GridSearchCV

Warning (from warnings module):
  File "D:\Anaconda3\lib\site-packages\sklearn\cross_validation.py", line 44
    "This module will be removed in 0.20.", DeprecationWarning)
DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.

Warning (from warnings module):
  File "D:\Anaconda3\lib\site-packages\sklearn\grid_search.py", line 43
    DeprecationWarning)
DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.
>>> from sklearn.model_selection import GridSearchCV
>>> n_neighbors_array = [1, 3, 5, 7, 10, 15]
>>> knn = KNeighborsClassifier()
>>> grid = GridSearchCV(knn, param_grid={'n_neighbors': n_neighbors_array})
>>> grid.fit(X_train, y_train)
GridSearchCV(cv=None, error_score='raise',
       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform'),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={'n_neighbors': [1, 3, 5, 7, 10, 15]},
       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,
       scoring=None, verbose=0)
>>> best_cv_err = 1 - grid.best_score_
>>> best_n_neighbors = grid.best_estimator_.n_neighbors
>>> print(best_cv_err, best_n_neighbors)
0.584357084357 7
>>> knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)
>>> knn.fit(X_train, y_train)
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=7, p=2,
           weights='uniform')
>>> err_train = np.mean(y_train != knn.predict(X_train))
>>> err_cv  = np.mean(y_cv  != knn.predict(X_cv))
>>> print(err_train, err_cv)
0.435298935299 0.60076408787
>>> from sklearn.svm import SVC
>>> svc = SVC()
>>> svc.fit(X_train, y_train)
SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
>>> err_train = np.mean(y_train != svc.predict(X_train))
>>> err_cv  = np.mean(y_cv  != svc.predict(X_cv))
>>> print (err_train, err_cv)
0.0 0.554918815664
>>> from sklearn.grid_search import GridSearchCV
>>> C_array = np.logspace(-3, 3, num=7)
>>> gamma_array = np.logspace(-5, 2, num=8)
>>> svc = SVC(kernel='rbf')
>>> grid = GridSearchCV(svc, param_grid={'C': C_array, 'gamma': gamma_array})
>>> grid.fit(X_train, y_train)
GridSearchCV(cv=None, error_score='raise',
       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={'C': array([  1.00000e-03,   1.00000e-02,   1.00000e-01,   1.00000e+00,
         1.00000e+01,   1.00000e+02,   1.00000e+03]), 'gamma': array([  1.00000e-05,   1.00000e-04,   1.00000e-03,   1.00000e-02,
         1.00000e-01,   1.00000e+00,   1.00000e+01,   1.00000e+02])},
       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)
>>> print ('CV error    = ', 1 - grid.best_score_)
CV error    =  0.5221130221130221
>>> print ('best C      = ', grid.best_estimator_.C)
best C      =  10.0
>>> print ('best gamma  = ', grid.best_estimator_.gamma)
best gamma  =  1e-05
>>> svc = SVC(kernel='rbf', C=grid.best_estimator_.C, gamma=grid.best_estimator_.gamma)
>>> svc.fit(X_train, y_train)
SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=1.0000000000000001e-05,
  kernel='rbf', max_iter=-1, probability=False, random_state=None,
  shrinking=True, tol=0.001, verbose=False)
>>> err_train = np.mean(y_train != svc.predict(X_train))
>>> err_cv  = np.mean(y_cv  != svc.predict(X_cv))
>>> print (err_train, err_cv)
0.438165438165 0.495702005731
>>> X_train.mean()
1.7744602225393789
>>> X_norm = (X-X.mean())/X.std()
>>> X_norm
array([[-0.25604886, -0.02175355,  0.0231742 , ...,  0.25537306,
        -0.06811325, -0.08511168],
       [ 0.08564478, -0.03732285, -0.03075022, ..., -0.10481122,
        -0.16070351, -0.04290481],
       [ 0.04610121, -0.30339468, -0.31456551, ...,  0.00691917,
        -0.14028599, -0.0871092 ],
       ..., 
       [-0.20280859,  0.06530312,  0.06401348, ..., -0.2416401 ,
        -0.07381155, -0.12136106],
       [-0.13110319, -0.25289986, -0.27139533, ...,  0.24335878,
        -0.10207441, -0.15216323],
       [-0.09919608, -0.05839417, -0.0375357 , ...,  0.06566748,
        -0.0641506 , -0.06678799]])
>>> X_norm.mean()
-9.7899203098890861e-18
>>> X_norm[:,0].mean()
-0.10446669196272565
>>> data = pandas.read_csv("x_train.csv", sep=';', header=None)
>>> data.shape
(3489, 223)
>>> data_y = pandas.read_csv("y_train.csv", sep=';', header=None)
>>> data.mean()
0       0.494704
1       0.516275
2       0.509534
3       0.496653
4       0.498532
5       0.511081
6       0.489582
7       0.517844
8       0.501379
9       3.018297
10      0.118684
11     -0.003736
12      0.515872
13      0.510597
14     25.054534
15      0.499310
16      0.495136
17      0.362352
18      0.487489
19      0.500750
20      0.496308
21      0.479929
22      0.471895
23      0.487453
24      2.992474
25     17.239064
26      0.496045
27      0.498817
28      0.489490
29      0.487396
         ...    
193     0.490738
194    23.843613
195     0.507632
196     0.500543
197     0.497728
198     0.478883
199     0.516969
200     0.008269
201     0.551334
202     2.965414
203    26.467747
204     0.471269
205     0.462031
206     0.499583
207     0.486639
208     0.489337
209     0.542498
210     0.469469
211     0.475815
212     0.537747
213     0.506315
214     0.488314
215     0.508792
216     0.516152
217     0.491506
218     0.520646
219     0.513619
220     0.491074
221     0.487143
222     0.494403
dtype: float64
>>> data_norm = (data-data.mean())/data.std()
>>> data.describe()
               0            1            2            3            4    \
count  3489.000000  3489.000000  3489.000000  3489.000000  3489.000000   
mean      0.494704     0.516275     0.509534     0.496653     0.498532   
std       1.344987     1.517720     1.944892     0.304816     0.288103   
min      -2.218093    -3.049841    -3.644502    -0.103472     0.000202   
25%      -0.589310    -0.527882    -0.794563     0.237865     0.256838   
50%       0.280815     0.596674     0.590149     0.497017     0.499785   
75%       1.416563     1.605525     1.862141     0.748879     0.749846   
max       4.744402     6.223512     8.318870     2.032806     0.999830   

               5            6            7            8            9    \
count  3489.000000  3489.000000  3489.000000  3489.000000  3489.000000   
mean      0.511081     0.489582     0.517844     0.501379     3.018297   
std       2.168340     1.745869     2.061410     0.455960     1.852894   
min      -6.311034    -3.112771    -3.924850    -0.567797    -1.517063   
25%      -1.053578    -0.971074    -0.899595     0.181897     1.547495   
50%       0.473108     0.188150     0.578649     0.473828     2.731865   
75%       2.052051     1.711705     1.955837     0.778593     4.174919   
max      10.749737     6.003011     9.384850     3.594312    10.741713   

          ...               213          214          215          216  \
count     ...       3489.000000  3489.000000  3489.000000  3489.000000   
mean      ...          0.506315     0.488314     0.508792     0.516152   
std       ...          1.823615     2.066324     2.231573     1.893010   
min       ...         -4.907867    -5.978127    -6.095323    -3.873535   
25%       ...         -0.838412    -1.013490    -1.243487    -0.799890   
50%       ...          0.313560     0.275163     0.153479     0.545157   
75%       ...          1.785158     1.845097     2.052449     1.817626   
max       ...          6.356287     8.144853     8.391595     8.026214   

               217          218          219          220          221  \
count  3489.000000  3489.000000  3489.000000  3489.000000  3489.000000   
mean      0.491506     0.520646     0.513619     0.491074     0.487143   
std       0.663052     2.859162     1.640211     2.798898     0.759490   
min      -1.449840    -5.190807    -4.348962    -6.242872    -1.650250   
25%       0.035183    -1.551566    -0.692253    -1.507348    -0.081461   
50%       0.458264     0.357019     0.398614     0.095635     0.486496   
75%       0.903188     2.460358     1.660167     2.295469     1.039252   
max       3.419200    16.147908     8.265469    15.120344     3.239605   

               222  
count  3489.000000  
mean      0.494403  
std       0.504922  
min      -0.805370  
25%       0.125037  
50%       0.457783  
75%       0.821512  
max       2.108298  

[8 rows x 223 columns]
>>> df_norm.mean()
Traceback (most recent call last):
  File "<pyshell#291>", line 1, in <module>
    df_norm.mean()
NameError: name 'df_norm' is not defined
>>> data_norm.mean()
0      1.038611e-15
1      7.033004e-16
2      4.345112e-17
3      1.235692e-15
4     -1.911340e-15
5      3.842982e-16
6     -6.511244e-16
7      8.954335e-17
8      3.463393e-15
9      2.413566e-15
10    -2.855746e-16
11    -2.783035e-16
12     2.397767e-16
13     2.293952e-16
14    -1.235644e-15
15    -2.816129e-16
16    -5.331712e-15
17    -1.317376e-17
18     9.056321e-16
19     6.127069e-16
20    -1.867491e-15
21    -5.741323e-16
22     1.672812e-16
23     1.691825e-16
24     7.196562e-16
25    -1.815814e-15
26    -5.045286e-16
27    -1.192543e-15
28    -1.671858e-16
29    -1.060265e-16
           ...     
193    1.287027e-16
194    1.050687e-15
195    4.100093e-16
196   -4.716459e-16
197   -2.003175e-15
198    8.159137e-16
199    2.236993e-16
200    8.480207e-18
201    6.411387e-16
202    1.492771e-15
203   -1.287066e-15
204    3.050329e-16
205    4.032633e-16
206   -5.197110e-16
207    4.831077e-15
208   -3.952127e-17
209    2.724247e-17
210   -4.758462e-16
211   -4.028496e-17
212    4.430829e-16
213   -2.425848e-16
214   -1.935015e-16
215   -1.925946e-16
216   -1.192320e-16
217    6.497700e-16
218   -6.634609e-18
219    2.225219e-16
220   -1.561440e-16
221   -2.786536e-16
222    9.746670e-16
dtype: float64
>>> data_norm.describe()
                0             1             2             3             4    \
count  3.489000e+03  3.489000e+03  3.489000e+03  3.489000e+03  3.489000e+03   
mean   1.038611e-15  7.033004e-16  4.345112e-17  1.235692e-15 -1.911340e-15   
std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   
min   -2.016969e+00 -2.349654e+00 -2.135869e+00 -1.968808e+00 -1.729693e+00   
25%   -8.059668e-01 -6.879771e-01 -6.705242e-01 -8.489969e-01 -8.389131e-01   
50%   -1.590266e-01  5.297419e-02  4.144938e-02  1.195500e-03  4.349242e-03   
75%    6.854038e-01  7.176890e-01  6.954660e-01  8.274696e-01  8.723085e-01   
max    3.159659e+00  3.760403e+00  4.015305e+00  5.039601e+00  1.739996e+00   

                5             6             7             8             9    \
count  3.489000e+03  3.489000e+03  3.489000e+03  3.489000e+03  3.489000e+03   
mean   3.842982e-16 -6.511244e-16  8.954335e-17  3.463393e-15  2.413566e-15   
std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   
min   -3.146238e+00 -2.063358e+00 -2.155173e+00 -2.344887e+00 -2.447717e+00   
25%   -7.215930e-01 -8.366355e-01 -6.876064e-01 -7.006787e-01 -7.937864e-01   
50%   -1.751253e-02 -1.726542e-01  2.949714e-02 -6.042286e-02 -1.545860e-01   
75%    7.106680e-01  7.000089e-01  6.975777e-01  6.079797e-01  6.242246e-01   
max    4.721886e+00  3.157986e+00  4.301429e+00  6.783341e+00  4.168299e+00   

           ...                213           214           215           216  \
count      ...       3.489000e+03  3.489000e+03  3.489000e+03  3.489000e+03   
mean       ...      -2.425848e-16 -1.935015e-16 -1.925946e-16 -1.192320e-16   
std        ...       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   
min        ...      -2.968929e+00 -3.129442e+00 -2.959399e+00 -2.318892e+00   
25%        ...      -7.373964e-01 -7.268001e-01 -7.852215e-01 -6.952107e-01   
50%        ...      -1.056997e-01 -1.031547e-01 -1.592209e-01  1.532257e-02   
75%        ...       7.012681e-01  6.566167e-01  6.917351e-01  6.875156e-01   
max        ...       3.207899e+00  3.705391e+00  3.532398e+00  3.967259e+00   

                217           218           219           220           221  \
count  3.489000e+03  3.489000e+03  3.489000e+03  3.489000e+03  3.489000e+03   
mean   6.497700e-16 -6.634609e-18  2.225219e-16 -1.561440e-16 -2.786536e-16   
std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   
min   -2.927894e+00 -1.997597e+00 -2.964607e+00 -2.405928e+00 -2.814248e+00   
25%   -6.882161e-01 -7.247620e-01 -7.351929e-01 -7.140034e-01 -7.486653e-01   
50%   -5.013543e-02 -5.722903e-02 -7.011580e-02 -1.412841e-01 -8.529228e-04   
75%    6.208887e-01  6.784195e-01  6.990251e-01  6.446805e-01  7.269459e-01   
max    4.415481e+00  5.465678e+00  4.726130e+00  5.226797e+00  3.624092e+00   

                222  
count  3.489000e+03  
mean   9.746670e-16  
std    1.000000e+00  
min   -2.574207e+00  
25%   -7.315298e-01  
50%   -7.252503e-02  
75%    6.478411e-01  
max    3.196327e+00  

[8 rows x 223 columns]
>>> X = np.array(data_mean)
Traceback (most recent call last):
  File "<pyshell#294>", line 1, in <module>
    X = np.array(data_mean)
NameError: name 'data_mean' is not defined
>>> data_test = pandas.read_csv("x_test.csv", sep=';', header=None)
>>> data_test_norm = (data_test-data_test.mean())/data_test.std()
>>> data_test_norm.describe()
                0             1             2             3             4    \
count  2.327000e+03  2.327000e+03  2.327000e+03  2.327000e+03  2.327000e+03   
mean   1.917962e-16 -1.864526e-16  1.061081e-16 -2.050549e-15 -2.419971e-15   
std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   
min   -1.815736e+00 -2.266528e+00 -2.089403e+00 -1.906902e+00 -1.735354e+00   
25%   -8.362150e-01 -6.962281e-01 -6.970064e-01 -8.453217e-01 -8.554680e-01   
50%   -1.635596e-01  2.648491e-02  3.487392e-02 -3.954229e-03  7.196305e-03   
75%    6.808149e-01  7.252150e-01  7.233023e-01  8.413434e-01  8.488592e-01   
max    3.714977e+00  3.520492e+00  3.095844e+00  4.395703e+00  1.747892e+00   

                5             6             7             8             9    \
count  2.327000e+03  2.327000e+03  2.327000e+03  2.327000e+03  2.327000e+03   
mean  -5.993034e-17 -5.668006e-16  4.332112e-17 -3.399372e-16 -8.046851e-16   
std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   
min   -2.493986e+00 -1.873572e+00 -2.121443e+00 -2.428418e+00 -2.580170e+00   
25%   -7.131156e-01 -8.280902e-01 -7.113150e-01 -7.104799e-01 -8.274144e-01   
50%   -2.231052e-02 -1.516302e-01  1.083151e-02 -5.032981e-02 -1.544978e-01   
75%    6.891523e-01  6.839362e-01  6.956760e-01  5.830980e-01  6.642500e-01   
max    1.132805e+01  3.850229e+00  3.334328e+00  7.567544e+00  3.826740e+00   

           ...                213           214           215           216  \
count      ...       2.327000e+03  2.327000e+03  2.327000e+03  2.327000e+03   
mean       ...      -4.149381e-16  4.460931e-16  5.651307e-16 -4.513412e-17   
std        ...       1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   
min        ...      -2.248220e+00 -2.295498e+00 -2.237706e+00 -2.231277e+00   
25%        ...      -7.322031e-01 -7.545418e-01 -7.753363e-01 -7.188230e-01   
50%        ...      -9.806886e-02 -6.691041e-02 -1.705780e-01  6.913512e-03   
75%        ...       6.805198e-01  6.580505e-01  7.120477e-01  7.070511e-01   
max        ...       1.186672e+01  3.489803e+00  8.342412e+00  3.489184e+00   

                217           218           219           220           221  \
count  2.327000e+03  2.327000e+03  2.327000e+03  2.327000e+03  2.327000e+03   
mean   1.979806e-16  2.407471e-16  7.061152e-18  3.944703e-16 -3.767697e-16   
std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   
min   -2.641511e+00 -1.949222e+00 -2.637932e+00 -2.360421e+00 -2.436742e+00   
25%   -6.509138e-01 -7.079673e-01 -7.415739e-01 -6.985444e-01 -7.410671e-01   
50%   -3.678298e-02 -2.691431e-02 -6.547749e-02 -1.249227e-01 -5.077258e-04   
75%    5.474896e-01  6.815186e-01  6.641578e-01  6.540499e-01  6.785968e-01   
max    1.598742e+01  3.466016e+00  3.815771e+00  4.873171e+00  1.119835e+01   

                222  
count  2.327000e+03  
mean  -2.919548e-15  
std    1.000000e+00  
min   -2.543238e+00  
25%   -7.172030e-01  
50%   -6.162264e-02  
75%    6.152208e-01  
max    4.696664e+00  

[8 rows x 223 columns]
>>> X = np.array(data_norm)
>>> X.shape
(3489, 223)
>>> X_test = np.array(data_test_norm)
>>> y = np.array(data_y)
>>> y.shape
(3489, 1)
>>> y = y.ravel()
>>> y.shape
(3489,)
>>> X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 11)
>>> knn = KNeighborsClassifier()
>>> knn.fit(X_train, y_train)
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
>>> y_train_predict = knn.predict(X_train)
>>> y_cv_predict = knn.predict(X_cv)
>>> X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size = 0.3, random_state = 11)
>>> X_cv.shape
(1047, 223)
>>> knn = KNeighborsClassifier()
>>> knn.fit(X_train, y_train)
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
>>> y_train_predict = knn.predict(X_train)
>>> y_cv_predict = knn.predict(X_cv)
>>> err_train = np.mean(y_train != y_train_predict)
>>> err_cv  = np.mean(y_cv  != y_cv_predict)
>>> print(err_train,err_cv)
0.341932841933 0.499522445081
>>> n_neighbors_array = [1, 3, 5, 7, 10, 15]
>>> knn = KNeighborsClassifier()
>>> grid = GridSearchCV(knn, param_grid={'n_neighbors': n_neighbors_array})
>>> grid.fit(X_train, y_train)
GridSearchCV(cv=None, error_score='raise',
       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform'),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={'n_neighbors': [1, 3, 5, 7, 10, 15]},
       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)
>>> best_cv_err = 1 - grid.best_score_
>>> best_n_neighbors = grid.best_estimator_.n_neighbors
>>> print (best_cv_err, best_n_neighbors)
0.4995904995904996 15
>>> knn = KNeighborsClassifier(n_neighbors=best_n_neighbors)
>>> knn.fit(X_train, y_train)
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=15, p=2,
           weights='uniform')
>>> err_train = np.mean(y_train != knn.predict(X_train))
>>> err_cv  = np.mean(y_cv  != knn.predict(X_cv))
>>> print (err_train, err_cv)
0.411547911548 0.492836676218
>>> svc = SVC()
>>> svc.fit(X_train, y_train)
SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
>>> err_train = np.mean(y_train != svc.predict(X_train))
>>> err_cv  = np.mean(y_cv  != svc.predict(X_cv))
>>> print (err_train, err_cv)
0.331695331695 0.462273161414
>>> C_array = np.logspace(-3, 3, num=7)
>>> gamma_array = np.logspace(-5, 2, num=8)
>>> svc = SVC(kernel='rbf')
>>> grid = GridSearchCV(svc, param_grid={'C': C_array, 'gamma': gamma_array})
>>> grid.fit(X_train, y_train)
GridSearchCV(cv=None, error_score='raise',
       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={'C': array([  1.00000e-03,   1.00000e-02,   1.00000e-01,   1.00000e+00,
         1.00000e+01,   1.00000e+02,   1.00000e+03]), 'gamma': array([  1.00000e-05,   1.00000e-04,   1.00000e-03,   1.00000e-02,
         1.00000e-01,   1.00000e+00,   1.00000e+01,   1.00000e+02])},
       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)
>>> print ('CV error    = ', 1 - grid.best_score_)
CV error    =  0.45864045864045866
>>> print ('best C      = ', grid.best_estimator_.C)
best C      =  100.0
>>> print ('best gamma  = ', grid.best_estimator_.gamma)
best gamma  =  0.0001
>>> svc = SVC(kernel='rbf', C=grid.best_estimator_.C, gamma=grid.best_estimator_.gamma)
>>> svc.fit(X_train, y_train)
SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
>>> err_train = np.mean(y_train != svc.predict(X_train))
>>> err_cv  = np.mean(y_cv  != svc.predict(X_test))
>>> err_cv  = np.mean(y_cv  != svc.predict(X_cv))
>>> print (err_train, err_cv)
0.389025389025 0.486150907354
>>> C_array
array([  1.00000000e-03,   1.00000000e-02,   1.00000000e-01,
         1.00000000e+00,   1.00000000e+01,   1.00000000e+02,
         1.00000000e+03])
>>> svc = SVC(kernel='linear')
>>> grid = GridSearchCV(svc, param_grid={'C': C_array})
>>> grid.fit(X_train, y_train)
Traceback (most recent call last):
  File "<pyshell#353>", line 1, in <module>
    grid.fit(X_train, y_train)
  File "D:\Anaconda3\lib\site-packages\sklearn\grid_search.py", line 829, in fit
    return self._fit(X, y, ParameterGrid(self.param_grid))
  File "D:\Anaconda3\lib\site-packages\sklearn\grid_search.py", line 573, in _fit
    for parameters in parameter_iterable
  File "D:\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py", line 758, in __call__
    while self.dispatch_one_batch(iterator):
  File "D:\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py", line 608, in dispatch_one_batch
    self._dispatch(tasks)
  File "D:\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py", line 571, in _dispatch
    job = self._backend.apply_async(batch, callback=cb)
  File "D:\Anaconda3\lib\site-packages\sklearn\externals\joblib\_parallel_backends.py", line 109, in apply_async
    result = ImmediateResult(func)
  File "D:\Anaconda3\lib\site-packages\sklearn\externals\joblib\_parallel_backends.py", line 326, in __init__
    self.results = batch()
  File "D:\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "D:\Anaconda3\lib\site-packages\sklearn\externals\joblib\parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "D:\Anaconda3\lib\site-packages\sklearn\cross_validation.py", line 1665, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "D:\Anaconda3\lib\site-packages\sklearn\svm\base.py", line 189, in fit
    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)
  File "D:\Anaconda3\lib\site-packages\sklearn\svm\base.py", line 256, in _dense_fit
    max_iter=self.max_iter, random_seed=random_seed)
TypeError: 'int' object is not callable
>>> C_array = np.logspace(-5, 2, num=8)
>>> gamma_array = np.logspace(-5, 2, num=8)
>>> degree_array = [2, 3, 4]
>>> svc = SVC(kernel='poly')
>>> grid = GridSearchCV(svc, param_grid={'C': C_array, 'gamma': gamma_array, 'degree': degree_array})
>>> X_train.shape
(2442, 223)
>>> y_train.shape
(2442,)
>>> grid.fit(X_train, y_train)
GridSearchCV(cv=None, error_score='raise',
       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False),
       fit_params={}, iid=True, n_jobs=1,
       param_grid={'C': array([  1.00000e-05,   1.00000e-04,   1.00000e-03,   1.00000e-02,
         1.00000e-01,   1.00000e+00,   1.00000e+01,   1.00000e+02]), 'gamma': array([  1.00000e-05,   1.00000e-04,   1.00000e-03,   1.00000e-02,
         1.00000e-01,   1.00000e+00,   1.00000e+01,   1.00000e+02]), 'degree': [2, 3, 4]},
       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)
>>> print ('CV error    = ', 1 - grid.best_score_)
CV error    =  0.4893529893529893
>>> print ('best C      = ', grid.best_estimator_.C)
best C      =  0.0001
>>> print ('best gamma  = ', grid.best_estimator_.gamma)
best gamma  =  0.1
>>> print ('best degree = ', grid.best_estimator_.degree)
best degree =  3
>>> svc = SVC(kernel='poly', C=grid.best_estimator_.C, 
          gamma=grid.best_estimator_.gamma, degree=grid.best_estimator_.degree)
>>> svc.fit(X_train, y_train)
SVC(C=0.0001, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=0.10000000000000001,
  kernel='poly', max_iter=-1, probability=False, random_state=None,
  shrinking=True, tol=0.001, verbose=False)
>>> err_train = np.mean(y_train != svc.predict(X_train))
>>> err_cv  = np.mean(y_cv  != svc.predict(X_cv))
>>> print (err_train, err_cv)
0.293202293202 0.481375358166
>>> rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=11)
Traceback (most recent call last):
  File "<pyshell#371>", line 1, in <module>
    rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=11)
NameError: name 'ensemble' is not defined
>>> rf = RandomForestClassifier(n_estimators=100, random_state=11)
>>> rf.fit(X_train, y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=100, n_jobs=1, oob_score=False, random_state=11,
            verbose=0, warm_start=False)
>>> err_train = np.mean(y_train != rf.predict(X_train))
>>> err_cv  = np.mean(y_cv  != rf.predict(X_cv))
>>> print (err_train, err_cv)
0.0 0.448901623687
>>> rf = ensemble.RandomForestClassifier(n_estimators=500, random_state=11)
Traceback (most recent call last):
  File "<pyshell#377>", line 1, in <module>
    rf = ensemble.RandomForestClassifier(n_estimators=500, random_state=11)
NameError: name 'ensemble' is not defined
>>> rf = RandomForestClassifier(n_estimators=500, random_state=11)
>>> rf.fit(X_train, y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=500, n_jobs=1, oob_score=False, random_state=11,
            verbose=0, warm_start=False)
>>> err_train = np.mean(y_train != rf.predict(X_train))
>>> err_cv  = np.mean(y_cv  != rf.predict(X_cv))
>>> print (err_train, err_cv)
0.0 0.450811843362
>>> rf = RandomForestClassifier(n_estimators=1500, random_state=11)
>>> rf.fit(X_train, y_train)
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_split=1e-07, min_samples_leaf=1,
            min_samples_split=2, min_weight_fraction_leaf=0.0,
            n_estimators=1500, n_jobs=1, oob_score=False, random_state=11,
            verbose=0, warm_start=False)
>>> err_train = np.mean(y_train != rf.predict(X_train))
>>> err_cv  = np.mean(y_cv  != rf.predict(X_cv))
>>> print (err_train, err_cv)
0.0 0.452722063037
>>> gbt = GradientBoostingClassifier(n_estimators=100, random_state=11)
>>> gbt.fit(X_train, y_train)
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=100, presort='auto', random_state=11,
              subsample=1.0, verbose=0, warm_start=False)
>>> err_train = np.mean(y_train != gbt.predict(X_train))
>>> err_cv  = np.mean(y_cv  != gbt.predict(X_cv))
>>> print (err_train, err_cv)
0.129811629812 0.461318051576
>>> gbt = GradientBoostingClassifier(n_estimators=500, random_state=11)
>>> gbt.fit(X_train, y_train)
GradientBoostingClassifier(criterion='friedman_mse', init=None,
              learning_rate=0.1, loss='deviance', max_depth=3,
              max_features=None, max_leaf_nodes=None,
              min_impurity_split=1e-07, min_samples_leaf=1,
              min_samples_split=2, min_weight_fraction_leaf=0.0,
              n_estimators=500, presort='auto', random_state=11,
              subsample=1.0, verbose=0, warm_start=False)
>>> 
KeyboardInterrupt
err_train = np.mean(y_train != gbt.predict(X_train))
>>> err_train = np.mean(y_train != gbt.predict(X_train))
>>> err_cv  = np.mean(y_cv  != gbt.predict(X_cv))
>>> print (err_train, err_cv)
0.0 0.469914040115
>>> y_train.shape
(2442,)
>>> 
